Steps,Policy/Entropy,Environment/Episode Length,Policy/Extrinsic Value Estimate,Environment/Cumulative Reward,Policy/Extrinsic Reward,Is Training
500,-9.014321,1.0,215.07243,-58.59366102103727,-58.59366102103727,1.0
1000,-9.014321,1.0,214.05946,-58.5937001953125,-58.5937001953125,1.0
1500,-9.014321,1.0,214.05946,-58.593693359375,-58.593693359375,1.0
2000,-9.014321,1.0,214.05946,-58.59370263671875,-58.59370263671875,1.0
2500,-9.014321,1.0,214.05946,-58.5936982421875,-58.5936982421875,1.0
3000,-9.014321,1.0,214.05946,-58.59369995117188,-58.59369995117188,1.0
3500,-9.014321,1.0,214.05946,-58.593695068359374,-58.593695068359374,1.0
4000,-9.014321,1.0,214.05946,-58.59369189453125,-58.59369189453125,1.0
4500,-9.014321,1.0,214.05946,-58.59369116210937,-58.59369116210937,1.0
5000,-9.014321,1.0,214.05946,-58.593704345703124,-58.593704345703124,1.0
5500,-9.014321,1.0,214.05946,-58.593697265625,-58.593697265625,1.0
6000,-9.014321,1.0,214.05946,-58.59369067382813,-58.59369067382813,1.0
6500,-9.014321,1.0,214.05946,-58.5936982421875,-58.5936982421875,1.0
7000,-9.014321,1.0,214.05946,-58.5937021484375,-58.5937021484375,1.0
7500,-9.014321,1.0,214.05946,-58.593693359375,-58.593693359375,1.0
8000,-9.014321,1.0,214.05946,-58.593697509765626,-58.593697509765626,1.0
8500,-9.014321,1.0,214.05946,-58.593698974609374,-58.593698974609374,1.0
9000,-9.014321,1.0,214.05946,-58.593700927734375,-58.593700927734375,1.0
9500,-9.014321,1.0,214.05946,-58.593693603515625,-58.593693603515625,1.0
10000,-9.014321,1.0,214.05946,-58.593700927734375,-58.593700927734375,1.0
10500,-9.014321,1.0,214.05946,-58.593704345703124,-58.593704345703124,1.0
11000,-9.014321,1.0,214.05946,-58.59369604492188,-58.59369604492188,1.0
11500,-9.014321,1.0,214.05946,-58.5936982421875,-58.5936982421875,1.0
12000,-9.014321,1.0,214.05946,-58.59369287109375,-58.59369287109375,1.0
